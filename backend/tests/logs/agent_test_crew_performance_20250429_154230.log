2025-04-29 15:42:30,703 - 94a7d13a - 0.14ms - 0.14ms - agent_test.crew_performance - INFO - Starting new test run with ID: 94a7d13a
2025-04-29 15:42:30,704 - 94a7d13a - 0.45ms - 0.63ms - agent_test.crew_performance - INFO - Processing query: What are the three types of machine learning algorithms?
2025-04-29 15:42:30,704 - 94a7d13a - 0.07ms - 0.72ms - agent_test.crew_performance - INFO - Using document: /Users/sreeramyashasviv/projects/MISC./AGENTIC-PLAYGROUND/document-query-app/backend/tests/data/sample1.txt
2025-04-29 15:44:20,493 - 94a7d13a - 109789.30ms - 109790.04ms - agent_test.crew_performance - INFO - Generated response: The three types of machine learning algorithms are supervised, unsupervised, and reinforcement learning.
2025-04-29 15:44:20,493 - 94a7d13a - 0.24ms - 109790.38ms - agent_test.crew_performance - INFO - Reference answer: The three types of machine learning algorithms are Supervised Learning, Unsupervised Learning, and Reinforcement Learning.
2025-04-29 15:44:20,494 - 94a7d13a - 0.14ms - 109790.57ms - agent_test.crew_performance - DEBUG - Calculating evaluation metrics
2025-04-29 15:44:20,507 - 94a7d13a - 12.95ms - 109803.52ms - agent_test.crew_performance - DEBUG - Calculated metrics: {'rouge1_f': 0.9285714285714286, 'rouge2_f': 0.7692307692307692, 'rougeL_f': 0.9285714285714286, 'bleu': 0.6933154254191038, 'key_points_hit_rate': 0.3333333333333333}
2025-04-29 15:44:20,507 - 94a7d13a - 0.07ms - 109803.59ms - agent_test.crew_performance - INFO - Evaluation metrics: {'rouge1_f': 0.9285714285714286, 'rouge2_f': 0.7692307692307692, 'rougeL_f': 0.9285714285714286, 'bleu': 0.6933154254191038, 'key_points_hit_rate': 0.3333333333333333}
2025-04-29 15:44:20,507 - 94a7d13a - 0.10ms - 109803.71ms - agent_test.crew_performance - INFO - Response quality meets thresholds
2025-04-29 15:44:20,507 - 94a7d13a - 0.08ms - 109803.80ms - agent_test.crew_performance - INFO - Processing query: What are the common evaluation metrics mentioned in the document?
2025-04-29 15:44:20,507 - 94a7d13a - 0.07ms - 109803.89ms - agent_test.crew_performance - INFO - Using document: /Users/sreeramyashasviv/projects/MISC./AGENTIC-PLAYGROUND/document-query-app/backend/tests/data/sample1.txt
2025-04-29 15:44:42,587 - 94a7d13a - 22079.77ms - 131883.68ms - agent_test.crew_performance - INFO - Generated response: Accuracy, precision, recall, F1-score, AUC, mean squared error (MSE), and precision-recall tradeoff curves are the common evaluation metrics discussed in the document.
2025-04-29 15:44:42,587 - 94a7d13a - 0.17ms - 131883.93ms - agent_test.crew_performance - INFO - Reference answer: The common evaluation metrics mentioned are Accuracy (percentage of correct predictions), Precision (True positives / (True positives + False positives)), Recall (True positives / (True positives + False negatives)), and F1 Score (Harmonic mean of precision and recall).
2025-04-29 15:44:42,587 - 94a7d13a - 0.12ms - 131884.08ms - agent_test.crew_performance - DEBUG - Calculating evaluation metrics
2025-04-29 15:44:42,588 - 94a7d13a - 1.34ms - 131885.42ms - agent_test.crew_performance - DEBUG - Calculated metrics: {'rouge1_f': 0.4827586206896552, 'rouge2_f': 0.14285714285714288, 'rougeL_f': 0.27586206896551724, 'bleu': 0.06916025538826995, 'key_points_hit_rate': 0.75}
2025-04-29 15:44:42,589 - 94a7d13a - 0.11ms - 131885.53ms - agent_test.crew_performance - INFO - Evaluation metrics: {'rouge1_f': 0.4827586206896552, 'rouge2_f': 0.14285714285714288, 'rougeL_f': 0.27586206896551724, 'bleu': 0.06916025538826995, 'key_points_hit_rate': 0.75}
2025-04-29 15:44:42,589 - 94a7d13a - 0.14ms - 131885.70ms - agent_test.crew_performance - INFO - Response quality meets thresholds
2025-04-29 15:44:42,589 - 94a7d13a - 0.10ms - 131885.83ms - agent_test.crew_performance - INFO - Processing query: What are the best practices for implementation?
2025-04-29 15:44:42,589 - 94a7d13a - 0.09ms - 131885.95ms - agent_test.crew_performance - INFO - Using document: /Users/sreeramyashasviv/projects/MISC./AGENTIC-PLAYGROUND/document-query-app/backend/tests/data/sample1.txt
